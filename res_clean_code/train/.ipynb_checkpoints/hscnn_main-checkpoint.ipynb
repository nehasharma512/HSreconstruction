{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import  os\n",
    "import scipy.io as sio\n",
    "\n",
    "from dataset import DatasetFromHdf5\n",
    "from resblock import resblock,conv_relu_res_relu_block\n",
    "from utils import AverageMeter,initialize_logger,save_checkpoint,record_loss\n",
    "from loss import rrmse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    # Dataset\n",
    "    train_data = DatasetFromHdf5('/home/lxy/project/ntire2018/hdf5/ntire_data/clean/train_si50_st80_246_clean.h5')\n",
    "    print(len(train_data))\n",
    "    val_data = DatasetFromHdf5('/home/lxy/project/ntire2018/hdf5/ntire_data/clean/test_si50_st50_patch_3to31.h5')\n",
    "    print(len(val_data))\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    train_data_loader = DataLoader(dataset=train_data, \n",
    "                                   num_workers=1,  \n",
    "                                   batch_size=64,\n",
    "                                   shuffle=True,\n",
    "                                   pin_memory=True)\n",
    "    val_loader = DataLoader(dataset=val_data,\n",
    "                            num_workers=1, \n",
    "                            batch_size=1,\n",
    "                            shuffle=False,\n",
    "                           pin_memory=True)\n",
    "\n",
    "    # Model               \n",
    "    model = resblock(conv_relu_res_relu_block, 16, 3,31)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "  \n",
    "    # Parameters, Loss and Optimizer\n",
    "    start_epoch = 0\n",
    "    end_epoch = 1000\n",
    "    init_lr = 0.0001\n",
    "    iteration = 0\n",
    "    record_test_loss = 1000\n",
    "    criterion = rrmse_loss\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=init_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    \n",
    "    model_path = '/home/lxy/codePractice/python/pytorch/model/res_16_onerelu/'\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    loss_csv = open(os.path.join(model_path,'loss.csv'), 'w+')\n",
    "    \n",
    "    log_dir = os.path.join(model_path,'train.log')\n",
    "    logger = initialize_logger(log_dir)\n",
    "    \n",
    "    # Resume\n",
    "    resume_file = '' \n",
    "    if resume_file:\n",
    "        if os.path.isfile(resume_file):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume_file))\n",
    "            checkpoint = torch.load(resume_file)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            iteration = checkpoint['iter']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "       \n",
    "    for epoch in range(start_epoch+1, end_epoch):\n",
    "        \n",
    "        start_time = time.time()         \n",
    "        train_loss, iteration, lr = train(train_data_loader, model, criterion, optimizer, iteration, init_lr, end_epoch)\n",
    "        test_loss = validate(val_loader, model, criterion)\n",
    "        \n",
    "        # save loss\n",
    "        record_loss(loss_csv,epoch, iteration,lr, train_loss, test_loss)\n",
    "        \n",
    "        # Save model\n",
    "        if test_loss < record_test_loss:\n",
    "            record_test_loss = test_loss\n",
    "            save_checkpoint(model_path, epoch, iteration, model, optimizer)\n",
    "        \n",
    "        # print loss \n",
    "        print (\"Epoch [%d], Iter[%d] Train Loss: %.9f Test Loss: %.9f learning rate : %.9f \" %(epoch, iteration, train_loss, test_loss, lr))\n",
    "        logger.info(\"Epoch [%d], Iter[%d] Train Loss: %.9f Test Loss: %.9f learning rate : %.9f \" %(epoch, iteration, train_loss, test_loss, lr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "def train(train_data_loader, model, criterion, optimizer, iteration, init_lr ,end_epoch):\n",
    "    losses = AverageMeter()\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        labels = labels.cuda(async=True)\n",
    "        images = images.cuda(async=True)\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)    \n",
    "        \n",
    "        # Decaying Learning Rate\n",
    "        \n",
    "        lr = poly_lr_scheduler(optimizer, init_lr, iteration, max_iter=968000, power=1.5) \n",
    "        iteration = iteration + 1\n",
    "        # Forward + Backward + Optimize       \n",
    "        output = model(images)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #  record loss\n",
    "        losses.update(loss.data[0])\n",
    "            \n",
    "    return losses.avg, iteration, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "def validate(val_loader, model, criterion):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        input = input.cuda(async=True)\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)      \n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        #  record loss\n",
    "        losses.update(loss.data[0])\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "def poly_lr_scheduler(optimizer, init_lr, iteraion, lr_decay_iter=1,\n",
    "                      max_iter=100, power=0.9):\n",
    "    \"\"\"Polynomial decay of learning rate\n",
    "        :param init_lr is base learning rate\n",
    "        :param iter is a current iteration\n",
    "        :param lr_decay_iter how frequently decay occurs, default is 1\n",
    "        :param max_iter is number of maximum iterations\n",
    "        :param power is a polymomial power\n",
    "\n",
    "    \"\"\"\n",
    "    if iteraion % lr_decay_iter or iteraion > max_iter:\n",
    "        return optimizer\n",
    "\n",
    "    lr = init_lr*(1 - iteraion/max_iter)**power\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'data', u'label']\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "61952\n",
      "[u'data', u'label']\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "7020\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "record_loss() takes exactly 7 arguments (6 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2436fc2ab63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9a91bd5322dc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# save loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mrecord_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: record_loss() takes exactly 7 arguments (6 given)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
